{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de datos usando Tensorflow\n",
    "\n",
    "Cuando trabajamos con Tensorflow, existen una gran variedad de formas en las que podemos alimentar los datos a nuestra red neuronal. Esto también tiene que ver con el tipo de datos y los pasos de pre-procesamiento que sean necesarios.\n",
    "\n",
    "Ante un problema de clasificación, lo primero que debemos hacer es **inspeccionar los datos y construir un prototipo de modelo**. La forma más fácil de hacerlo es con notebooks. Sin embargo, a la hora de llevar a cabo experimentos con redes neuronales, un entorno interactivo puede no ser la mejor opción. En primer lugar, explorar los hiperparámetros de una arquitectura neuronal puede llevar varias horas e incluso días, perdiendo todas las ventajas del entorno interactivo. En segundo lugar, no podemos encolar ejecuciones de notebooks para reservar recursos como las GPUs.\n",
    "\n",
    "Por ello, primero realizaremos una exploración inicial de los datos en esta notebook. Una vez que decidamos qué tipo de modelo implementar, pasaremos el modelo a un script de python que cargue los datos, construya el modelo, lo entrene, y finalmente guarde las métricas relevantes.\n",
    "\n",
    "En esta notebook, veremos varios conceptos avanzados de entrenamiento de redes:\n",
    "\n",
    "  * Uso de `tf.data.Dataset` para optimizar la ingesta de datos. \n",
    "  * Uso de capas `tf.layers.Embedding`.\n",
    "  * Combinación de distintos tipos de features en un mismo modelo con múltiples inputs.\n",
    "  * MLFlow para registro de experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "seaborn.set_style('whitegrid')\n",
    "seaborn.set_palette('colorblind')\n",
    "seaborn.set_context('paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando los datos\n",
    "\n",
    "Una vez más, estaremos trabajando con el conjunto de datos `petfinder`. Deben descargarlo siguiendo las instrucciones en la [notebook 0](./0_set_up.ipynb), descomprimirlo y luego ajustar la dirección en esta notebook según corresponda. \n",
    "\n",
    "Algunas de las preguntas que respondemos durante esta etapa son:\n",
    "\n",
    " * ¿Qué tipo de tarea tengo que resolver? ¿Clasificación o regresión?\n",
    " * ¿Qué distribución tienen mis etiquetas?\n",
    " * ¿Qué tipo de datos tengo disponible para la clasificación? ¿Cuáles son útiles?\n",
    " * Dadas las características disponibles y el problema que quiero resolver, ¿qué tipo de clasificador o arquitectura conviene utilizar? ¿De qué manera se están representando las causas latentes del problema en el modelo elegido?\n",
    " * Dadas las características disponibles y el modelo elegido, ¿de qué forma representaremos cada una de dichas características?\n",
    " \n",
    "En esta clase utilizaremos redes neuronales como modelos porque es el objetivo de la materia, pero sigue siendo importante qué aspectos podremos capturar con este tipo de modelo, especialmente para tener intuiciones sobre qué hiperparámetros explorar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = 'petfinder_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample of data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset, dev_dataset = train_test_split(\n",
    "    pandas.read_csv(os.path.join(DATA_DIRECTORY, 'train.csv')), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>Description</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8611</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>Rescued by Ms Rose. Female-2 mths+. Done 1st v...</td>\n",
       "      <td>4</td>\n",
       "      <td>12180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10419</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>Very healthy husky mix breed dog name BOSS wai...</td>\n",
       "      <td>4</td>\n",
       "      <td>14759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3690</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>254</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>About The Pet RESCUED STRAY KITTEN Newly rescu...</td>\n",
       "      <td>2</td>\n",
       "      <td>5225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "8611      2    2     266       0       2       1       7       0   \n",
       "10419     1   36     307       0       1       1       0       0   \n",
       "3690      2    3     254     265       2       1       2       7   \n",
       "\n",
       "       MaturitySize  FurLength  Vaccinated  Dewormed  Sterilized  Health  \\\n",
       "8611              2          1           1         1           2       1   \n",
       "10419             2          2           1         1           1       1   \n",
       "3690              1          2           2         1           2       1   \n",
       "\n",
       "       Quantity  Fee  State  \\\n",
       "8611          1    0  41401   \n",
       "10419         1    0  41401   \n",
       "3690          1    0  41401   \n",
       "\n",
       "                                             Description  AdoptionSpeed    PID  \n",
       "8611   Rescued by Ms Rose. Female-2 mths+. Done 1st v...              4  12180  \n",
       "10419  Very healthy husky mix breed dog name BOSS wai...              4  14759  \n",
       "3690   About The Pet RESCUED STRAY KITTEN Newly rescu...              2   5225  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type              int64\n",
       "Age               int64\n",
       "Breed1            int64\n",
       "Breed2            int64\n",
       "Gender            int64\n",
       "Color1            int64\n",
       "Color2            int64\n",
       "Color3            int64\n",
       "MaturitySize      int64\n",
       "FurLength         int64\n",
       "Vaccinated        int64\n",
       "Dewormed          int64\n",
       "Sterilized        int64\n",
       "Health            int64\n",
       "Quantity          int64\n",
       "Fee               int64\n",
       "State             int64\n",
       "Description      object\n",
       "AdoptionSpeed     int64\n",
       "PID               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'AdoptionSpeed'\n",
    "nlabels = dataset[target_col].unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribución de las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.countplot(dataset.AdoptionSpeed, color='blue')\n",
    "seaborn.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "\n",
    "https://www.tensorflow.org/tutorials/structured_data/feature_columns\n",
    "\n",
    "Why not to use feature_columns https://github.com/tensorflow/tensorflow/issues/27895\n",
    "\n",
    "feature_columns doc 2.0 https://www.tensorflow.org/api_docs/python/tf/feature_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteamos los valores de las semillas\n",
    "numpy.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando las representaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos una serie de variables categóricas y ordinales que pueden ser útiles para predecir la velocidad de adopción. Para cada una de ellas, tenemos que pensar cuál es la mejor forma de pasarla como input a la red. Analizaremos algunas de ellas:\n",
    "\n",
    "  * `Age` es una variable numérica discreta, podemos representarla con una única neurona con el valor original. Es muy importante normalizar este tipo de variables.\n",
    "  * `Gender` es una variable categórica. Como la variable tiene pocos valores, utilizaremos un *one-hot encoding* como representación.\n",
    "  * `Breed1` es una variable categórica que puede tomar muchos valores. Podemos utilizar *one-hot encoding*, lo cual resultará en vectores esparsos de dimensión cercana a 300. Alternativamente, podemos utilizar una capa de embedding para representar sus valores con un vector denso de baja dimesionalidad. Pregunta: ¿qué información podrá capturar este embedding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que definimos cómo vamos a representar cada una de las columnas, las pre-procesamos para formar un numpy array. En este caso, procesaremos el dataset completo porque estamos seguros de que entrará en memoria. En otros casos, puede ser necesario un pre-procesamiento por batches, o incluso utilizar las funciones de Tensorflow incluidas en el módulo `feature_column`.\n",
    "\n",
    "NOTA: para este ejercicio, intentamos utilizar `feature_column` pero causaba que la loss diverga. La documentación no ha sido totalmente actualizada a Tensorflow 2.0, y puede ser que nos encontremos ante un error de cambio de versiones. Pueden encontrar más ejemplos en [este link](https://www.tensorflow.org/tutorials/structured_data/feature_columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's important to always use the same one-hot length\n",
    "one_hot_columns = {\n",
    "    one_hot_col: dataset[one_hot_col].max()\n",
    "    for one_hot_col in ['Gender', 'Color1', 'MaturitySize', 'FurLength',\n",
    "                        'Vaccinated', 'Dewormed', 'Sterilized', 'Health']\n",
    "}\n",
    "embedded_columns = {\n",
    "    embedded_col: dataset[embedded_col].max() + 1\n",
    "    for embedded_col in ['Breed1']\n",
    "}\n",
    "numeric_columns = ['Age', 'Fee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features(df, targets=True):\n",
    "    direct_features = []\n",
    "\n",
    "    # Create one hot encodings\n",
    "    for one_hot_col, max_value in one_hot_columns.items():\n",
    "        direct_features.append(tf.keras.utils.to_categorical(df[one_hot_col] - 1, max_value))\n",
    "\n",
    "    # Create and append numeric columns\n",
    "    # Don't forget to normalize!\n",
    "    cs = MinMaxScaler()\n",
    "    direct_features.append(cs.fit_transform(df[numeric_columns]))\n",
    "    # Concatenate all features that don't need further embedding into a single matrix.\n",
    "    features = {'direct_features': numpy.hstack(direct_features)}\n",
    "\n",
    "    # Create embedding columns - nothing to do here. We will use the zero embedding for OOV\n",
    "    for embedded_col in embedded_columns.keys():\n",
    "        features[embedded_col] = df[embedded_col].values\n",
    "\n",
    "    # Convert labels to one-hot encodings\n",
    "    if targets:\n",
    "        targets = tf.keras.utils.to_categorical(df[target_col], nlabels)\n",
    "        return features, targets\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = process_features(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'direct_features': array([[0.        , 1.        , 0.        , ..., 0.        , 0.00784314,\n",
       "         0.        ],\n",
       "        [1.        , 0.        , 0.        , ..., 0.        , 0.14117647,\n",
       "         0.        ],\n",
       "        [0.        , 1.        , 0.        , ..., 0.        , 0.01176471,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [1.        , 0.        , 0.        , ..., 0.        , 0.03921569,\n",
       "         0.        ],\n",
       "        [0.        , 1.        , 0.        , ..., 0.        , 0.04705882,\n",
       "         0.02666667],\n",
       "        [1.        , 0.        , 0.        , ..., 0.        , 0.09411765,\n",
       "         0.        ]]),\n",
       " 'Breed1': array([266, 307, 254, ..., 213, 307, 307], dtype=int64)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direct_features_input_shape = (X_train['direct_features'].shape[1],)\n",
    "direct_features_input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando datasets iterables\n",
    "\n",
    "Como hemos visto, las redes neuronales se entrenan iterativamente con el algoritmo de *stochastic gradient descent*. Una forma de hacerlo es pasarle el dataset entero al método `fit` de un modelo de Keras, como vimos en la notebook anterior. Sin embargo, esto tiene algunas desventajas:\n",
    "\n",
    "* El dataset procesado debe entrar en memoria\n",
    "* El dataset procesado debe entrar en disco, lo cual no siempre es factible para encodings y datasets realmente grandes (ej: la wikipedia)\n",
    "* Una vez que la GPU ha terminado de procesar los datos, devuelve el control a la CPU (que estaba esperando sin hacer nada), y espera a que los nuevos datos son particionados.\n",
    "* No es posible usar cálculo distribuido en distintos file systems.\n",
    "\n",
    "Las dos primeras desventajas se solucionan preprocesando los datos en batches, y creando matrices anchas pero con pocas filas. Sin embargo, escribir este código manualmente puede ser complejo y en general lo hacemos de manera ineficiente. Solucionar las dos últimas es bastante más complicado y a la vez crítico. \n",
    "\n",
    "> **No importa qué tan buen hardware usemos para el entrenamiento del modelo, si seguimos limitados por un procesamiento de datos lineal y single core.**\n",
    "\n",
    "Por eso es recomendable utilizar las abstracciones nativas provistas por Tensorflow que paralelizan internamente muchas funciones.\n",
    "\n",
    "Para ello, crearemos un objeto `tf.data.Dataset` iterable a partir de nuestro dataframe de pandas y no tendremos que preocuparnos por la optimización de la GPU. Los datasets saben cómo crear batches, shuffles, aplicar funciones map y filter, etc. Además, podemos crear datasets a partir de diversas estructuras de datos, como numpy arrays o archivos. Pueden encontrar más información sobre los distintos tipos de Datasets en [este tutorial](https://towardsdatascience.com/how-to-use-dataset-in-tensorflow-c758ef9e4428)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# TODO shuffle the train dataset!\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(process_features(dev_dataset)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver qué es lo que tiene adentro en dataset obteniendo la primera operación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'direct_features': <tf.Tensor: id=21, shape=(32, 31), dtype=float64, numpy=\n",
       "  array([[0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.00784314,\n",
       "          0.        ],\n",
       "         [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.14117647,\n",
       "          0.        ],\n",
       "         [0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.01176471,\n",
       "          0.        ],\n",
       "         [0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.00784314,\n",
       "          0.        ],\n",
       "         [0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.01568627,\n",
       "          0.        ],\n",
       "         [0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.01176471,\n",
       "          0.        ],\n",
       "         [0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.00392157,\n",
       "          0.        ],\n",
       "         [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.01176471,\n",
       "          0.01666667],\n",
       "         [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.00392157,\n",
       "          0.        ],\n",
       "         [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.04705882,\n",
       "          0.        ],\n",
       "         [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.01176471,\n",
       "          0.        ],\n",
       "         [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 1.        , 0.        , 0.        , 0.02352941,\n",
       "          0.        ],\n",
       "         [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.00784314,\n",
       "          0.        ],\n",
       "         [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.37647059,\n",
       "          0.        ],\n",
       "         [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.01960784,\n",
       "          0.        ],\n",
       "         [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.09411765,\n",
       "          0.03333333],\n",
       "         [0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.00784314,\n",
       "          0.        ],\n",
       "         [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.02352941,\n",
       "          0.        ],\n",
       "         [0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.00392157,\n",
       "          0.        ],\n",
       "         [0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.01176471,\n",
       "          0.05      ],\n",
       "         [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.00392157,\n",
       "          0.        ],\n",
       "         [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.18823529,\n",
       "          0.        ],\n",
       "         [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 1.        , 0.        , 0.        , 0.01568627,\n",
       "          0.16666667],\n",
       "         [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.01960784,\n",
       "          0.        ],\n",
       "         [0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.09411765,\n",
       "          0.        ],\n",
       "         [0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.00784314,\n",
       "          0.        ],\n",
       "         [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.04705882,\n",
       "          0.        ],\n",
       "         [0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.00784314,\n",
       "          0.        ],\n",
       "         [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.01176471,\n",
       "          0.        ],\n",
       "         [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.00392157,\n",
       "          0.        ],\n",
       "         [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.06666667,\n",
       "          0.06666667],\n",
       "         [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "          0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "          1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "          0.        , 1.        , 0.        , 0.        , 0.14117647,\n",
       "          0.        ]])>,\n",
       "  'Breed1': <tf.Tensor: id=20, shape=(32,), dtype=int64, numpy=\n",
       "  array([266, 307, 254, 307, 266, 307, 307, 307, 266, 266, 239, 266, 307,\n",
       "         179, 266, 205, 307, 266, 266, 307, 307, 128, 205, 265, 190, 307,\n",
       "         292, 303, 307, 252, 205, 307], dtype=int64)>},\n",
       " <tf.Tensor: id=22, shape=(32, 5), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]], dtype=float32)>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch, y_batch = next(iter(train_ds))\n",
    "x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo el modelo\n",
    "\n",
    "Construimos el modelo, por ahora con sólo una capa oculta. Sin embargo, la complejidad más grande es combinar los features que tienen embeddings con los que no. Por cada tipo de feature, tenemos que agregar una capa de `Input`. Tener en cuenta que cada embedded feature se considera distinto.\n",
    "\n",
    "Como tenemos más de un input, tenemos que usar la API funcional de Keras en lugar de usar un modelo `Sequential`. La API funcional puede construir modelos más flexibles, ya que conectaremos explícitamente cada capa con su capa siguiente.\n",
    "\n",
    "Pueden encontrar otro ejemplo similar a este código en [esta notebook](https://www.kaggle.com/alexanderkireev/deep-learning-support-9663)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding embedding of size 77 for layer Breed1\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "hidden_layer_size = 64\n",
    "\n",
    "# Add one input and one embedding for each embedded column\n",
    "embedding_layers = []\n",
    "inputs = []\n",
    "for embedded_col, max_value in embedded_columns.items():\n",
    "    input_layer = layers.Input(shape=(1,), name=embedded_col)\n",
    "    inputs.append(input_layer)\n",
    "    # Define the embedding layer\n",
    "    embedding_size = int(max_value / 4)\n",
    "    embedding_layers.append(\n",
    "        tf.squeeze(layers.Embedding(input_dim=max_value, output_dim=embedding_size)(input_layer), axis=-2))\n",
    "    print('Adding embedding of size {} for layer {}'.format(embedding_size, embedded_col))\n",
    "\n",
    "# Add the direct features already calculated\n",
    "direct_features_input = layers.Input(shape=direct_features_input_shape, name='direct_features')\n",
    "inputs.append(direct_features_input)\n",
    "    \n",
    "# Concatenate everything together\n",
    "features = layers.concatenate(embedding_layers + [direct_features_input])\n",
    "\n",
    "dense1 = layers.Dense(hidden_layer_size, activation='relu')(features)\n",
    "output_layer = layers.Dense(nlabels, activation='softmax')(dense1)\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de evaluación\n",
    "\n",
    "Al igual que en la materia de aprendizaje supervisado, utilizaremos el accuracy como métrica, y agregaremos el score f1. Es opcional implementar esta predicción como un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Breed1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 77)        23716       Breed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 77)]         0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "direct_features (InputLayer)    [(None, 31)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 108)          0           tf_op_layer_Squeeze[0][0]        \n",
      "                                                                 direct_features[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           6976        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            325         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 31,017\n",
      "Trainable params: 31,017\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando el modelo\n",
    "\n",
    "Una vez que tenemos definido nuestro modelo, tenemos que entrenarlo. Sin embargo, para que los resultados sean útiles, tenemos que llevar un registro de qué hiperparámetros utilizamos y qué performance obtuvimos. Para eso, usaremos [MLFlow](https://mlflow.org/docs/latest/quickstart.html), una librería muy simple pero que permite sistematizar el registro de resultados.\n",
    "\n",
    "MLFlow soporta muchísimos casos de uso, pero por ahora sólo usaremos el más básico de todos para organizar el entrenamiento. Llamaremos *experiments* a los cambios grandes en la arquitectura, por ejemplo, si agregamos muchas capas nuevas o mecanismos de regularización. Llamaremos *runs* a las distintas ejecuciones de la misma arquitectura donde variamos sólo algunos hiperparámetros, como funciones de activación, cantidad de neuronas, tamaños de los embeddings, etc.\n",
    "\n",
    "Para acceder a la interfaz gráfica donde podemos ver las *run*, en una nueva terminal tenemos que ejecutar \n",
    "\n",
    "    $ mlflow ui -p PORT\n",
    "    \n",
    "Y abrir `https://localhost:PORT` en nuestro navegador (donde `PORT` es un número de puerto). Si estamos en un servidor, es probab, tendremos que abrir un nuevo puerto ssh a `PORT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({direct_features: (None, 31), Breed1: (None,)}, (None, 5)), types: ({direct_features: tf.float64, Breed1: tf.int64}, tf.float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'very_base_approach' does not exist. Creating a new experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019/10/20 10:34:37 WARNING mlflow.tracking.context.git_context: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "265/265 [==============================] - 16s 61ms/step - loss: 1.4409 - accuracy: 0.3222\n",
      "Epoch 2/10\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.3991 - accuracy: 0.3587\n",
      "Epoch 3/10\n",
      "265/265 [==============================] - 4s 15ms/step - loss: 1.3849 - accuracy: 0.3718\n",
      "Epoch 4/10\n",
      "265/265 [==============================] - 3s 13ms/step - loss: 1.3743 - accuracy: 0.3818\n",
      "Epoch 5/10\n",
      "265/265 [==============================] - 3s 13ms/step - loss: 1.3649 - accuracy: 0.3870\n",
      "Epoch 6/10\n",
      "265/265 [==============================] - 4s 14ms/step - loss: 1.3564 - accuracy: 0.3915\n",
      "Epoch 7/10\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.3490 - accuracy: 0.3952\n",
      "Epoch 8/10\n",
      "265/265 [==============================] - 3s 12ms/step - loss: 1.3419 - accuracy: 0.3986\n",
      "Epoch 9/10\n",
      "265/265 [==============================] - 3s 13ms/step - loss: 1.3353 - accuracy: 0.4043\n",
      "Epoch 10/10\n",
      "265/265 [==============================] - 4s 15ms/step - loss: 1.3291 - accuracy: 0.4098\n",
      "67/67 [==============================] - 8s 119ms/step - loss: 1.4276 - accuracy: 0.3444\n",
      "*** Test loss: 1.427592633375481 - accuracy: 0.3443552255630493\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment('very_base_approach')\n",
    "\n",
    "with mlflow.start_run(nested=True):\n",
    "    # Log model hiperparameters first\n",
    "    mlflow.log_param('hidden_layer_size', hidden_layer_size)\n",
    "    mlflow.log_param('embedded_columns', embedded_columns)\n",
    "    mlflow.log_param('one_hot_columns', one_hot_columns)\n",
    "    mlflow.log_param('numeric_columns', numeric_columns)\n",
    "    \n",
    "    # Train\n",
    "    epochs = 10\n",
    "    history = model.fit(train_ds, epochs=epochs)\n",
    "    \n",
    "    # Evaluate\n",
    "    loss, accuracy = model.evaluate(test_ds)\n",
    "    print(\"*** Test loss: {} - accuracy: {}\".format(loss, accuracy))\n",
    "    mlflow.log_metric('epochs', epochs)\n",
    "    mlflow.log_metric('loss', loss)\n",
    "    mlflow.log_metric('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluando del modelo\n",
    "\n",
    "Además de tener en cuenta las métricas de performance del modelo, es importante mirar los resultados obtenidos y controlar que el modelo efectivamente está aprendiendo algo relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luz_4\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py:364: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  if isinstance(inputs, collections.Sequence):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21cf1ef9f48>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = numpy.argmax(model.predict(test_ds), axis=1)\n",
    "seaborn.countplot(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lo primero que hicimos fue correr el ejercicio de la misma forma que lo habíamos visto en clase. Al hacer esto, el accuracy obtenido fue de 0.311.\n",
    "- Probamos aumentar el número de epochs a 50, lo cual aumentó el tiempo de procesamiento, pero los resultados no mejoraron demasiado. Se obtuvo un 0.335 de accuracy. Por lo tanto decidimos seguir corriendo con 10 epochs.\n",
    "- Luego agregamos las columnas numéricas Age y Fee (normalizadas utilizando MinMaxScaler), lo cual mejoró muy poco el resultado obtenido anteriormente, con un valor de 0.333.\n",
    "- Luego agregamos el resto de las variables categóricas. Al agregar estas variables, la accuracy aumentó notoriamente a un 0.372.\n",
    "- También probamos agregar la columna numérica Quantity, pero al hacer esto, la accuracy disminuyó del 0.372 obtenido anteriormente a 0.36.\n",
    "- Por último, probamos correr con 50 epochs el modelo utilizando las variables categóricas mencionadas anteriormnente (con las que se había obtenido un accuracy de 0.372). Al hacer esto, notamos que el accuracy en el conjunto de entrenamiento subía a medida que pasaban las epochs, sin embargo, nuestro modelo claramente resultó estar haciendo over-fitting para el conjunto de entrenamiento, ya que el accuracy para el conjunto de testing fue de 0.326."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiando hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Breed1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 77)        23716       Breed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 77)]         0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "direct_features (InputLayer)    [(None, 31)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 108)          0           tf_op_layer_Squeeze[0][0]        \n",
      "                                                                 direct_features[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           6976        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            325         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 31,017\n",
      "Trainable params: 31,017\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='SGD',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({direct_features: (None, 31), Breed1: (None,)}, (None, 5)), types: ({direct_features: tf.float64, Breed1: tf.int64}, tf.float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 1.3109 - accuracy: 0.4236\n",
      "Epoch 2/10\n",
      "265/265 [==============================] - 4s 16ms/step - loss: 1.3087 - accuracy: 0.4261\n",
      "Epoch 3/10\n",
      "265/265 [==============================] - 4s 14ms/step - loss: 1.3077 - accuracy: 0.4271\n",
      "Epoch 4/10\n",
      "265/265 [==============================] - 4s 15ms/step - loss: 1.3070 - accuracy: 0.4274\n",
      "Epoch 5/10\n",
      "265/265 [==============================] - 3s 11ms/step - loss: 1.3064 - accuracy: 0.4269\n",
      "Epoch 6/10\n",
      "265/265 [==============================] - 4s 14ms/step - loss: 1.3058 - accuracy: 0.4274\n",
      "Epoch 7/10\n",
      "265/265 [==============================] - 4s 13ms/step - loss: 1.3052 - accuracy: 0.4272\n",
      "Epoch 8/10\n",
      "265/265 [==============================] - 4s 15ms/step - loss: 1.3046 - accuracy: 0.4273\n",
      "Epoch 9/10\n",
      "265/265 [==============================] - 3s 11ms/step - loss: 1.3041 - accuracy: 0.4275\n",
      "Epoch 10/10\n",
      "265/265 [==============================] - 3s 11ms/step - loss: 1.3036 - accuracy: 0.4280\n",
      "67/67 [==============================] - 7s 112ms/step - loss: 1.4255 - accuracy: 0.3576\n",
      "*** Test loss: 1.4254607762863387 - accuracy: 0.3575814962387085\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment('very_base_approach')\n",
    "\n",
    "with mlflow.start_run(nested=True):\n",
    "    # Log model hiperparameters first\n",
    "    mlflow.log_param('hidden_layer_size', hidden_layer_size)\n",
    "    mlflow.log_param('embedded_columns', embedded_columns)\n",
    "    mlflow.log_param('one_hot_columns', one_hot_columns)\n",
    "    mlflow.log_param('numeric_columns', numeric_columns)\n",
    "    \n",
    "    # Train\n",
    "    epochs = 10\n",
    "    history = model.fit(train_ds, epochs=epochs)\n",
    "    \n",
    "    # Evaluate\n",
    "    loss, accuracy = model.evaluate(test_ds)\n",
    "    print(\"*** Test loss: {} - accuracy: {}\".format(loss, accuracy))\n",
    "    mlflow.log_metric('epochs', epochs)\n",
    "    mlflow.log_metric('loss', loss)\n",
    "    mlflow.log_metric('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21cf37caf88>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = numpy.argmax(model.predict(test_ds), axis=1)\n",
    "seaborn.countplot(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pandas.read_csv(os.path.join(DATA_DIRECTORY, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    process_features(test_dataset, targets=False)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = numpy.argmax(model.predict(final_test_dataset), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pandas.DataFrame(list(zip(test_dataset.PID, predictions)), columns=[\"PID\", \"AdoptionSpeed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(DATA_DIRECTORY, 'results.csv'), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
